{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Ego4D download videos"
   ],
   "metadata": {
    "id": "Ua65wq2BAJz3"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 1: Install Ego4D CLI\n",
    "!pip install git+https://github.com/facebookresearch/Ego4d.git#egg=ego4d"
   ],
   "metadata": {
    "id": "IfKSeU26AIFh"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install awscli\n",
    "import os\n",
    "os.environ[\"PATH\"] += \":/root/.local/bin\"\n",
    "!aws --version"
   ],
   "metadata": {
    "id": "DsCtCjiPEnAw"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "# Replace these with your actual credentials\n",
    "aws_access_key = \"\"\n",
    "aws_secret_key = \"\"\n",
    "aws_region = \"us-east-1\"  # Or your preferred region\n",
    "\n",
    "# Create AWS config and credentials paths\n",
    "aws_dir = os.path.expanduser(\"~/.aws\")\n",
    "os.makedirs(aws_dir, exist_ok=True)\n",
    "\n",
    "# Write to ~/.aws/credentials\n",
    "with open(os.path.join(aws_dir, \"credentials\"), \"w\") as f:\n",
    "    f.write(f\"\"\"[default]\n",
    "aws_access_key_id = {aws_access_key}\n",
    "aws_secret_access_key = {aws_secret_key}\n",
    "\"\"\")\n",
    "\n",
    "# Write to ~/.aws/config\n",
    "with open(os.path.join(aws_dir, \"config\"), \"w\") as f:\n",
    "    f.write(f\"\"\"[default]\n",
    "region = {aws_region}\n",
    "output = json\n",
    "\"\"\")\n",
    "\n",
    "print(\"✅ AWS default profile created!\")\n"
   ],
   "metadata": {
    "id": "5SSWnPRvFNCW"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON file\n",
    "with open('egotempo_openQA.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Lists to store unique IDs\n",
    "video_uids = set()\n",
    "video_clip_uids = set()\n",
    "\n",
    "# Iterate over the annotations and extract video ID and clip ID\n",
    "for annotation in data['annotations']:\n",
    "    clip_id = annotation['clip_id']\n",
    "\n",
    "    # Handle .mp4 suffix if exists\n",
    "    if clip_id.endswith('.mp4'):\n",
    "        clip_id = clip_id[:-4]  # Remove the last 4 chars\n",
    "\n",
    "    # Extract video_id (before first '_') for video_uids\n",
    "    video_id = clip_id.split('_')[0]\n",
    "    video_uids.add(video_id)\n",
    "\n",
    "    # Full clip_id (with _start_end timestamps) goes into video_clip_uids\n",
    "    video_clip_uids.add(clip_id)\n",
    "\n",
    "# Save video IDs (only the base video names)\n",
    "with open('video_uids.txt', 'w') as f:\n",
    "    for video_id in sorted(video_uids):\n",
    "        f.write(video_id + '\\n')\n",
    "\n",
    "# Save clip IDs (full clip names without .mp4)\n",
    "with open('video_clip_uids.txt', 'w') as f:\n",
    "    for clip_id in sorted(video_clip_uids):\n",
    "        f.write(clip_id + '\\n')\n",
    "\n",
    "print(f\"Extracted {len(video_uids)} unique video IDs to 'video_uids.txt'.\")\n",
    "print(f\"Extracted {len(video_clip_uids)} unique clip IDs to 'video_clip_uids.txt'.\")\n"
   ],
   "metadata": {
    "id": "DGpZcWl9Pnwv"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Read the video UIDs into a list\n",
    "with open('video_uids.txt', 'r') as f:\n",
    "    video_uids = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "# Join them into a space-separated string\n",
    "video_uids_str = ' '.join(video_uids)\n",
    "\n",
    "# Now run the command\n",
    "!ego4d --video_uids {video_uids_str} \\\n",
    "       -o ./ego4d_clips --datasets video_540ss --yes\n"
   ],
   "metadata": {
    "id": "u1-jb-EmDSVB"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Trim videos"
   ],
   "metadata": {
    "id": "fXs-cSdbAd0r"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# === CONFIG ===\n",
    "input_txt = \"video_clip_uids.txt\"           # Your .txt file\n",
    "output_dir = \"./trimmed_clips\"              # Final trimmed videos\n",
    "raw_download_dir = \"./ego4d_clips/v2/video_540ss\"          # Raw downloaded videos\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(raw_download_dir, exist_ok=True)\n",
    "\n",
    "# === Function to download and trim ===\n",
    "def download_and_trim(line):\n",
    "    line = line.strip()\n",
    "    if not line:\n",
    "        return  # Skip empty lines\n",
    "\n",
    "    try:\n",
    "        parts = line.split('_')\n",
    "        if len(parts) < 3:\n",
    "            raise ValueError(\"Line doesn't match expected format: videoid_start_end\")\n",
    "\n",
    "        # Handle cases with more underscores in video ID\n",
    "        video_id = '_'.join(parts[:-2])\n",
    "        start = float(parts[-2])\n",
    "        end = float(parts[-1])\n",
    "\n",
    "        clip_name = f\"{video_id}_{start}_{end}.mp4\"\n",
    "        output_path = os.path.join(output_dir, clip_name)\n",
    "        raw_video_path = os.path.join(raw_download_dir, f\"{video_id}.mp4\")\n",
    "\n",
    "        # Trim with ffmpeg\n",
    "        print(f\"Trimming {video_id} from {start} to {end}...\")\n",
    "        subprocess.run([\n",
    "            \"ffmpeg\", \"-y\", \"-i\", raw_video_path,\n",
    "            \"-ss\", str(start), \"-to\", str(end),\n",
    "            \"-c\", \"copy\", output_path\n",
    "        ], check=True)\n",
    "\n",
    "        print(f\"Saved: {output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing '{line}': {e}\")\n",
    "\n",
    "# === Run for all lines ===\n",
    "with open(input_txt, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    download_and_trim(line)\n"
   ],
   "metadata": {
    "id": "_XFOwUnRAfRa"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Extract frames from clips"
   ],
   "metadata": {
    "id": "pkNfJHwmMFHG"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def extract_uniform_frames(video_path, base_output_dir, num_frames=32):\n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"Video path does not exist: {video_path}\")\n",
    "        return\n",
    "\n",
    "    video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "    output_dir = os.path.join(base_output_dir, video_name)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    print(f\"Extracting frames from: {video_path}\")\n",
    "    print(f\"Saving to: {output_dir}\")\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    if total_frames < num_frames:\n",
    "        print(f\"Video has only {total_frames} frames. Extracting all of them.\")\n",
    "        frame_indices = np.linspace(0, total_frames - 1, total_frames, dtype=int)\n",
    "    else:\n",
    "        frame_indices = np.linspace(0, total_frames - 1, num_frames, dtype=int)\n",
    "\n",
    "    print(f\"Extracting frames at indices: {frame_indices}\")\n",
    "\n",
    "    extracted = 1\n",
    "    for i in range(total_frames):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if i in frame_indices:\n",
    "            frame_name = f\"frame_{extracted:06d}.jpg\"\n",
    "            cv2.imwrite(os.path.join(output_dir, frame_name), frame)\n",
    "            extracted += 1\n",
    "\n",
    "    cap.release()\n",
    "    print(f\"✅ Done! Extracted {extracted - 1} frames to {output_dir}\\n\")\n",
    "\n",
    "\n",
    "# === Apply to all videos ===\n",
    "trimmed_dir = \"/content/trimmed_clips\"\n",
    "output_base_dir = \"/content/extracted_frames\"\n",
    "\n",
    "for filename in os.listdir(trimmed_dir):\n",
    "    if filename.endswith(\".mp4\"):\n",
    "        video_path = os.path.join(trimmed_dir, filename)\n",
    "        extract_uniform_frames(video_path, output_base_dir)"
   ],
   "metadata": {
    "id": "9X0HJQ8RtFgF"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evaluate using Gemini"
   ],
   "metadata": {
    "id": "20a3yrJTUCPq"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uIawDWwrEBW1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import ast\n",
    "import base64\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import google.generativeai as genai\n",
    "\n",
    "\n",
    "class Config:\n",
    "    OUTPUT_DIR = './results/'\n",
    "    DATA_FILE = './egotempo_openQA.json'  # Updated to JSON file\n",
    "    GEMINI_API_KEY = ''\n",
    "    MODEL_NAME = 'gemini-1.5-flash'\n",
    "    TEMPERATURE = 0.0\n",
    "    MAX_WORKERS = 1\n",
    "    BATCH_SIZE = 1\n",
    "    SHUFFLE_DATA = False\n",
    "    RESULT_FILE_TEMPLATE = 'results.json'\n",
    "\n",
    "\n",
    "class QADataset:\n",
    "    def __init__(self, data_file):\n",
    "        with open(data_file, 'r') as f:\n",
    "            raw = json.load(f)\n",
    "            self.annotations = raw[\"annotations\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.annotations[index]\n",
    "        video_id = row['clip_id']\n",
    "        question = row['question']\n",
    "        category = row['question_type']\n",
    "        answer = row['answer']\n",
    "\n",
    "        question_str = (\n",
    "            f\"These are frames from a video that I want to upload. \"\n",
    "            f\"Use the visual cues to answer the question: {question}. \"\n",
    "            f\"You need to answer the question in any case and not demand additional context information. \"\n",
    "            f\"Note: All actions mentioned refer to the person recording the video.\"\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'video_id': video_id,\n",
    "            'question_answer': question_str,\n",
    "            'question': question,\n",
    "            'answer': answer,\n",
    "            'category': category\n",
    "        }\n",
    "\n",
    "\n",
    "def load_images_as_base64(frames_dir):\n",
    "    image_paths = sorted([f for f in os.listdir(frames_dir) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
    "    images_b64 = []\n",
    "    for image in image_paths:\n",
    "        with open(os.path.join(frames_dir, image), 'rb') as img_file:\n",
    "            b64_image = base64.b64encode(img_file.read()).decode('utf-8')\n",
    "            images_b64.append({\n",
    "                \"mime_type\": \"image/jpeg\",\n",
    "                \"data\": b64_image\n",
    "            })\n",
    "    return images_b64[:1]  # Limiting to 1 frame\n",
    "\n",
    "\n",
    "def call_gemini_model(model, images, text_prompt):\n",
    "    response = model.generate_content(\n",
    "        contents=[{\"role\": \"user\", \"parts\": images + [{\"text\": text_prompt}]}],\n",
    "    )\n",
    "    return response.text\n",
    "\n",
    "\n",
    "def process_qa_item(batch, model, existing_entries):\n",
    "    uid = batch['video_id']\n",
    "    question = batch['question']\n",
    "    question_answer = batch['question_answer']\n",
    "    category = batch['category']\n",
    "    answer = batch['answer']\n",
    "\n",
    "    if (uid, question) in existing_entries:\n",
    "        return None\n",
    "\n",
    "    frames_dir = f'/content/extracted_frames/{uid}'\n",
    "    if not os.path.exists(frames_dir):\n",
    "        print(f\"Frames directory not found: {frames_dir}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        images = load_images_as_base64(frames_dir)\n",
    "        output_text = call_gemini_model(model, images, question_answer)\n",
    "        print(output_text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {uid}: {e}\")\n",
    "        return None\n",
    "\n",
    "    return {\n",
    "        \"V\": uid,\n",
    "        \"Q\": question,\n",
    "        \"QA\": question_answer,\n",
    "        \"A\": output_text,\n",
    "        \"C\": answer,\n",
    "        \"M\": category\n",
    "    }\n",
    "\n",
    "\n",
    "def perform_bulk_inference(dataset, model, output_file_path):\n",
    "    results = []\n",
    "    existing_entries = set()\n",
    "\n",
    "    if os.path.exists(output_file_path):\n",
    "        with open(output_file_path, 'r') as f:\n",
    "            try:\n",
    "                existing_data = json.load(f)\n",
    "                results = [entry for entry in existing_data if entry[\"A\"] != \"\"]\n",
    "                existing_entries = {(entry[\"V\"], entry[\"Q\"]) for entry in results}\n",
    "            except Exception as e:\n",
    "                print(\"Error loading previous results:\", e)\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=Config.MAX_WORKERS) as executor:\n",
    "        futures = {\n",
    "            executor.submit(process_qa_item, dataset[i], model, existing_entries): i\n",
    "            for i in range(len(dataset))\n",
    "        }\n",
    "\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Running Inference\"):\n",
    "            result = future.result()\n",
    "            if result:\n",
    "                results.append(result)\n",
    "                if len(results) % 50 == 0:\n",
    "                    with open(output_file_path, 'w') as f:\n",
    "                        json.dump(results, f)\n",
    "\n",
    "    with open(output_file_path, 'w') as f:\n",
    "        json.dump(results, f)\n",
    "    print(f\"Saved {len(results)} results to {output_file_path}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    genai.configure(api_key=Config.GEMINI_API_KEY)\n",
    "    model = genai.GenerativeModel(Config.MODEL_NAME)\n",
    "\n",
    "    os.makedirs(Config.OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    dataset = QADataset(Config.DATA_FILE)\n",
    "    output_file_path = os.path.join(Config.OUTPUT_DIR, Config.RESULT_FILE_TEMPLATE)\n",
    "    perform_bulk_inference(dataset, model, output_file_path)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evaluate the results"
   ],
   "metadata": {
    "id": "GsASt0IF-KSM"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import ast\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import google.generativeai as genai\n",
    "\n",
    "\n",
    "GEMINI_API_KEY = ''\n",
    "MODEL_NAME = 'gemini-1.5-flash'\n",
    "OUTPUT_EVAL_DIR = './eval_results/'\n",
    "MAX_WORKERS = 5\n",
    "\n",
    "\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "model = genai.GenerativeModel(MODEL_NAME)\n",
    "\n",
    "\n",
    "def create_prompt(q, a, pred):\n",
    "    return f\"\"\"role: \"system\",\n",
    "content: \"You are an intelligent chatbot designed for evaluating the correctness of AI assistant predictions for question-answer pairs.\n",
    "Your task is to compare the predicted answer with the ground-truth answer and determine if the predicted answer is correct or not. Here's how you can accomplish the task:\n",
    "-----##INSTRUCTIONS:\n",
    "- Focus on the correctness and accuracy of the predicted answer with the ground-truth.\n",
    "- Consider uncertain predictions, such as 'it is impossible to answer the question from the video', as incorrect, unless the ground truth answer also says that.\"\n",
    "role: \"user\",\n",
    "content: \"Please evaluate the following video-based question-answer pair:\n",
    "Question: {q}\n",
    "Ground truth correct Answer: {a}\n",
    "Predicted Answer: {pred}\n",
    "Provide your evaluation as a correct/incorrect prediction along with the score where the score is an integer value between 0 (fully wrong) and 5 (fully correct). The middle score provides the percentage of correctness.\n",
    "Please generate the response in the form of a Python dictionary string with keys 'pred', 'score' and 'reason', where value of 'pred' is a string of 'correct' or 'incorrect',\n",
    "value of 'score' is in INTEGER, not STRING and value of 'reason' should provide the reason behind the decision.\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def evaluate_with_gemini(qa_item):\n",
    "    question = qa_item['Q']\n",
    "    answer = qa_item['C']\n",
    "    pred = qa_item['A']\n",
    "\n",
    "    prompt = create_prompt(question, answer, pred)\n",
    "\n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        match = re.search(r'\\{.*?\\}', response.text, re.DOTALL)\n",
    "        if match:\n",
    "            eval_dict = ast.literal_eval(match.group(0))\n",
    "            return {\n",
    "                \"pred\": eval_dict.get(\"pred\", \"\"),\n",
    "                \"score\": int(eval_dict.get(\"score\", 0)),\n",
    "                \"reason\": eval_dict.get(\"reason\", \"\")\n",
    "            }\n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating: {e}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def evaluate_predictions(input_path, output_path):\n",
    "    with open(input_path, \"r\") as f:\n",
    "        raw_data = json.load(f)\n",
    "\n",
    "    print(f\"Loaded {len(raw_data)} QA pairs from {input_path}\")\n",
    "\n",
    "    results = []\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        futures = list(tqdm(executor.map(evaluate_with_gemini, raw_data), total=len(raw_data)))\n",
    "\n",
    "    for idx, result in enumerate(futures):\n",
    "        if result:\n",
    "            results.append([result, raw_data[idx]])\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "    print(f\"Saved evaluated results to {output_path}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    input_dir = './results/'\n",
    "    output_dir = OUTPUT_EVAL_DIR\n",
    "\n",
    "    for file_name in os.listdir(input_dir):\n",
    "        if file_name.endswith(\".json\"):\n",
    "            input_path = os.path.join(input_dir, file_name)\n",
    "            output_subdir = os.path.join(output_dir, file_name.replace(\".json\", \"\"))\n",
    "            output_path = os.path.join(output_subdir, \"eval_results.json\")\n",
    "            evaluate_predictions(input_path, output_path)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "metadata": {
    "id": "lDy5OFKR5GxF"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}